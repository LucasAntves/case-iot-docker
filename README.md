# IoT Sensor Streaming Pipeline

Solu√ß√£o de Engenharia de Dados para simula√ß√£o, ingest√£o, processamento e visualiza√ß√£o de dados de sensores IoT em tempo real. Este projeto simula um ambiente de Big Data escal√°vel, resiliente e seguro, utilizando tecnologias de ponta conteinerizadas.

---

## Arquitetura da Solu√ß√£o

A arquitetura foi projetada seguindo o padr√£o de microsservi√ßos e processamento de stream (Streaming ETL). O objetivo √© garantir que os dados gerados pelos sensores sejam coletados, processados e disponibilizados para an√°lise com lat√™ncia m√≠nima, garantindo integridade e toler√¢ncia a falhas.

### Diagrama de Fluxo de Dados

```mermaid
graph TD
    subgraph Host ["üíª Sua M√°quina (Host)"]
        Browser("üåê Navegador Web<br/>(Dashboard)")
    end

    subgraph Docker ["üê≥ Infraestrutura Docker (Docker Compose)"]
        style Docker fill:#f0f8ff,stroke:#005f9e,stroke-width:2pxb
        
        subgraph Network ["üîó Rede Interna: iot-network"]
            style Network fill:#fff,stroke:#666,stroke-dasharray: 5 5
            
            Producer("üêç <b>Sensor Producer</b><br/>Container Python<br/>(Gera Dados)")
            
            subgraph Streaming ["‚ö° Camada de Ingest√£o"]
                style Streaming fill:#e8f5e9,stroke:#2e7d32
                Zookeeper("üêò Zookeeper")
                Kafka("üì® <b>Apache Kafka</b><br/>Broker")
            end
            
            Spark("‚ö° <b>Spark Consumer</b><br/>PySpark Streaming<br/>(Processamento)")
            
            Postgres[("üõ¢Ô∏è <b>PostgreSQL</b><br/>Armazenamento")]
            
            Metabase("üìä <b>Metabase</b><br/>Visualiza√ß√£o")
        end
    end

    %% Conex√µes e Fluxos (TODOS CORRIGIDOS COM ASPAS)
    Producer -- "1. Envia JSON (TCP/29092)" --> Kafka
    Zookeeper -. "Gerencia Cluster" .-> Kafka
    Kafka -- "2. Leitura de Stream" --> Spark
    Spark -- "3. Grava√ß√£o JDBC (Porta 5432)" --> Postgres
    Metabase -- "4. Consultas SQL" --> Postgres
    
    %% Acesso Externo (CORRIGIDO AQUI TAMB√âM)
    Browser -. "Acesso HTTP (Porta 3000)" .-> Metabase
```

### Stack
Gerador de Dados (Producer): Script em Python 3.9 (biblioteca Faker) simulando dispositivos IoT com envio em alta frequ√™ncia.

Ingest√£o (Message Broker): Apache Kafka + Zookeeper. Atua como buffer de resili√™ncia, desacoplando produ√ß√£o e consumo.

Processamento (Consumer): Apache Spark (PySpark) operando em Structured Streaming. Aplica Schema Enforcement (tipagem forte) e regras de neg√≥cio.

Armazenamento (Serving Layer): PostgreSQL. Banco relacional para persist√™ncia transacional e integra√ß√£o com BI.

Visualiza√ß√£o (BI): Metabase. Dashboard interativo para monitoramento em tempo real (atualiza√ß√£o autom√°tica a cada 60s).

Infraestrutura: Docker & Docker Compose. Garante a orquestra√ß√£o e reprodutibilidade do ambiente.


#### Detalhes da Implementa√ß√£o

1. Seguran√ßa e Configura√ß√£o
Vari√°veis de Ambiente: Nenhuma credencial (senhas de banco) est√° exposta no c√≥digo fonte (hardcoded). Todas as configura√ß√µes sens√≠veis s√£o injetadas via os.getenv atrav√©s do Docker Compose.

Automa√ß√£o (IaC): O banco de dados e o dashboard de BI s√£o provisionados automaticamente via scripts SQL (init.sql e backup) mapeados nos volumes do Docker.

2. Ingest√£o e Produtor (src/producer)
Simula√ß√£o Realista: Gera dados de Temperatura, Umidade e Status para cidades espec√≠ficas (ex: S√£o Paulo, Recife, Curitiba).

Performance: Otimizado para enviar m√∫ltiplos eventos por segundo, preenchendo os gr√°ficos de s√©rie temporal sem "buracos".

3. Processamento (src/consumer)
Integridade de Dados: O Spark aplica um schema r√≠gido (TimestampType, DoubleType). Dados fora do formato s√£o tratados antes da persist√™ncia.

Persist√™ncia Eficiente: Utiliza a estrat√©gia foreachBatch para grava√ß√µes otimizadas via driver JDBC no PostgreSQL.

### Como Executar o Projeto
Pr√©-requisitos:  
[Docker e Docker Compose](https://www.docker.com/get-started/)
 instalados
#### Passo a Passo 
1. Clone o reposit√≥rio utilizando o comando abaixo:  
git clone https://github.com/LucasAntves/case-iot-docker.git

2. V√° para a pasta do projeto que acabou de clonar e abra o terminal.

3. Com o terminal aberto na **raiz do projeto**, execute o seguinte comando:

```bash
docker compose up --build -d
```

4. Caso precise desligar os container e limpar tudo que foi gravado no postgres, use este comando
```bash
docker compose down -v
```

#### Acessando a tabela e o Dashboard:

Com nossos containers rodando e nossos dados sendo gerados, vamos usar nossa ferramenta de visualiza√ß√£o:

Aguarde cerca de 1 minuto para a inicializa√ß√£o total do Metabase.

Acesse no navegador: http://localhost:3000

Login: admin@project.com

Senha: admin321

(Nota: O login acima √© pr√©-configurado via script de automa√ß√£o).

**Monitoramento via Terminal**  
Voc√™ pode acompanhar o fluxo de dados em tempo real pelos logs:
Faremos pelo terminal na raiz do projeto.

***Ver envio de dados:***  
Antes de ver o log, precisamos checar como nossa producer est√° no docker, para isso execute:  
```bash
docker ps
```
O nome estar√° na coluna 'NAMES'. Assim que encontrar o nome da sua producer, rode o comando abaixo sem ( )

```bash
docker logs -f (NOME DA PRODUCER)
```

***Ver processamento Spark:***
```bash
 docker logs -f spark-consumer
```


***Escalabilidade da producer:***  
Esse comando servir√° para escalar nossa producer, podemos gerar mais dados e checar como o kafka √≠r√° se comportar.

```bash
 docker compose up -d --scale sensor-producer=3
```

#### O que vai acontecer?
O Docker vai criar nome-producer-1  
O Docker vai criar nome-producer-2  
O Docker vai criar nome-producer-3

Caso tenha aumentado a produ√ß√£o de dados e queira checar, podemos visualizar no Kafdrop atrav√©s do caminho:  
http://localhost:9000

Abra o t√≥pico sensores-iot e cheque o size, atualize a p√°gina e teremos os n√∫meros atualizados

#### Ap√≥s o teste, podemos desligar algumas producers:  
```bash
docker stop NOME-PRODUCER
docker rm NOME-PRODUCER
```


### Testes e Valida√ß√£o
O projeto conta com uma su√≠te de testes automatizados (unittest).

#### Configura√ß√£o do Ambiente Virtual (Python)

Para executar os scripts locais ou rodar os testes unit√°rios, recomenda-se criar um ambiente virtual para isolar as depend√™ncias.

**1. Crie o ambiente virtual:**

Na raiz do projeto, execute:  
```bash
python -m venv venv
```

**2. Ative o ambiente:**

```bash
Windows (PowerShell):  
.\venv\Scripts\activate
```
Linux / Mac:
```bash
source venv/bin/activate
```

**3. Instale as depend√™ncias:**

pip install -r requirements.txt
(Ap√≥s a instala√ß√£o, o comando python -m unittest ... funcionar√° corretamente).

**Com seu ambiente virtual configurado, vamos aos testes:**
```bash
python -m unittest discover tests -v
```
Cobertura:  
Unit√°rios: Valida√ß√£o de schema JSON, tipagem de dados e regras de neg√≥cio (limites de temperatura).

Integra√ß√£o: Valida√ß√£o da conex√£o com Kafka (envio e recebimento real de mensagens).

### Sobre o Dashboard (Analytics)
O painel do Metabase j√° vem pr√©-configurado e inclui:

* KPIs em Tempo Real: Temperatura e Umidade m√©dias atuais.

* Monitoramento de Status: Tabela de cidades ordenada por criticidade (Vermelho/Cr√≠tico no topo).

* S√©ries Temporais: Gr√°fico de linhas comparativo mostrando a evolu√ß√£o da temperatura por cidade minuto a minuto.

* (O Dashboard possui Auto-Refresh configurado para atualizar a cada 60 segundos).

### Melhorias Futuras (Roadmap)
Pontos identificados para evolu√ß√£o da arquitetura em um cen√°rio de escala massiva:

**Camada de Data Lake (Raw):** Implementar grava√ß√£o paralela em Amazon S3 ou DynamoDB para armazenamento de dados brutos a longo prazo.  

**Orquestra√ß√£o:** Adicionar Apache Airflow para gerenciar jobs batch complementares, como a limpeza de dados antigos do banco relacional ou o retreinamento de modelos de Machine Learning baseados no hist√≥rico dos sensores.

**Observabilidade:** Implementar Prometheus e Grafana para monitorar a sa√∫de dos containers (CPU/Mem√≥ria) e o lag de consumo do Kafka.
